{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:54.153174Z",
     "start_time": "2018-02-02T13:59:52.844135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, TensorBoard\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input \n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import load_model\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:54.158213Z",
     "start_time": "2018-02-02T13:59:54.154805Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "classes = 10\n",
    "batch_size= 60\n",
    "image_size = 224\n",
    "train_total = 10000\n",
    "validation_total = 4370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:54.302792Z",
     "start_time": "2018-02-02T13:59:54.159828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CACNN_basic_block(x):\n",
    "    x = Conv2D(8, (3,3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(16, (3,3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3,3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3,3), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:55.428332Z",
     "start_time": "2018-02-02T13:59:54.304529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input((image_size,image_size,3))\n",
    "\n",
    "x1 = Conv2D(4, (3,3), padding='valid')(x)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = CACNN_basic_block(x1)\n",
    "\n",
    "x2 = Conv2D(4, (5,5), padding='valid')(x)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = CACNN_basic_block(x2)\n",
    "\n",
    "x3 = Conv2D(4, (7,7), padding='valid')(x)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = CACNN_basic_block(x3)\n",
    "\n",
    "y = layers.concatenate([x1,x2,x3])\n",
    "#y = Dropout(0.3)(y)\n",
    "y = Dense(256, activation='relu')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dense(128, activation='relu')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dense(classes, activation='softmax')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:55.454720Z",
     "start_time": "2018-02-02T13:59:55.429962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 222, 222, 4)  112         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 220, 220, 4)  304         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 218, 218, 4)  592         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 222, 222, 4)  16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 220, 220, 4)  16          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 218, 218, 4)  16          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 220, 220, 8)  296         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 218, 218, 8)  296         batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 216, 216, 8)  296         batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 220, 220, 8)  32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 218, 218, 8)  32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 216, 216, 8)  32          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 220, 220, 8)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 218, 218, 8)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 216, 216, 8)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 110, 110, 8)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 109, 109, 8)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 108, 108, 8)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 108, 108, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 107, 107, 16) 1168        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 106, 106, 16) 1168        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 108, 108, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 107, 107, 16) 64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 106, 106, 16) 64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 108, 108, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 107, 107, 16) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 106, 106, 16) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 54, 54, 16)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 53, 53, 16)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 53, 53, 16)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 32)   4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 51, 51, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 51, 51, 32)   4640        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 51, 51, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 51, 51, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 52, 52, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 51, 51, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 51, 51, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 26, 26, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 25, 25, 32)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 25, 25, 32)   0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 24, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 23, 23, 64)   18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 23, 23, 64)   18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 24, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 23, 23, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 23, 23, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 24, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 23, 23, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 23, 23, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 11, 11, 64)   0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 11, 11, 64)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 128)    73856       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 9, 9, 128)    73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 9, 9, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 9, 9, 128)    512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 9, 9, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 9, 9, 128)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 5, 5, 128)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 128)    0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 4, 4, 128)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 128)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 128)          0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 128)          0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384)          0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128)          512         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1290        batch_normalization_20[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 433,682\n",
      "Trainable params: 431,402\n",
      "Non-trainable params: 2,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = Model(inputs=x,outputs=y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:55.581682Z",
     "start_time": "2018-02-02T13:59:55.456151Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:59:55.747466Z",
     "start_time": "2018-02-02T13:59:55.585180Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:20.952614Z",
     "start_time": "2018-02-02T13:59:55.749333Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9081 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    'train',\n",
    "                    target_size=(image_size,image_size),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:21.361368Z",
     "start_time": "2018-02-02T14:01:20.953737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4370 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                        '../validation_224/',\n",
    "                        target_size=(image_size,image_size),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical',\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_crop(image, crop_size):\n",
    "    h,w,d = image.shape\n",
    "    rand_num_h = random.randint(0,h-crop_size)\n",
    "    rand_num_w = random.randint(0,w-crop_size)\n",
    "    image_crop = image[rand_num_h:rand_num_h+crop_size,rand_num_w:rand_num_w+crop_size,:]\n",
    "    return image_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_crop_valid(image, crop_size):\n",
    "    h,w,d = image.shape\n",
    "    image_crop = image[h//2-crop_size//2:h//2+crop_size//2,w//2-crop_size//2:w//2+crop_size//2,:]\n",
    "    \n",
    "    return image_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:21.558021Z",
     "start_time": "2018-02-02T14:01:21.385827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gen(train_files, train_classes, batch_size, target_size, imggen):\n",
    "    min_batch_size = batch_size //10\n",
    "    train_data = list(zip(train_files, train_classes))\n",
    "    train_data_dict = defaultdict(list)\n",
    "    for i in range(len(train_data)):\n",
    "        train_data_dict[train_data[i][0].split('/')[0]].append(train_data[i])\n",
    "       \n",
    "    while(True):\n",
    "        for i in train_data_dict.keys():\n",
    "            random.shuffle(train_data_dict[i])\n",
    "        for start in range(0, len(train_data), min_batch_size):\n",
    "            image_crop_list = []\n",
    "            image_classes_list = []\n",
    "            for j in train_data_dict.keys():\n",
    "                end = min(start + min_batch_size, len(train_data_dict[j])) \n",
    "    \n",
    "                for i in range(start,end):\n",
    "                    image_classes_list.append(train_data_dict[j][i][1])\n",
    "                \n",
    "                x_batch = [train_data_dict[j][i][0] for i in range(start,end)]\n",
    "                for i in x_batch:\n",
    "                    image = mpimg.imread('train/' + i)\n",
    "                    image = random_crop(image,image_size)\n",
    "                    if(np.random.rand()<0.5):\n",
    "                        image = np.rot90(image,1,(0,1))\n",
    "                    image_crop_list.append(image)\n",
    "                    del image\n",
    "                    \n",
    "            \n",
    "            if(len(image_classes_list)<batch_size-2*min_batch_size):\n",
    "                break\n",
    "            \n",
    "            image_crop_list = [x/1. for x in image_crop_list]\n",
    "            image_crop_list = [imggen.random_transform(x) for x in image_crop_list]\n",
    "            image_crop_list = [preprocess_input(x) for x in image_crop_list]\n",
    "            \n",
    "            x_batch = np.array(image_crop_list, np.float32)\n",
    "            y_batch = np.array(image_classes_list)         \n",
    "            \n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:21.766256Z",
     "start_time": "2018-02-02T14:01:21.560969Z"
    }
   },
   "outputs": [],
   "source": [
    "train_crop_generator = train_gen(train_generator.filenames,to_categorical(train_generator.classes),batch_size,image_size,train_datagen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:21.814982Z",
     "start_time": "2018-02-02T14:01:21.767497Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_gen(valid_files, valid_classes, batch_size, target_size, imggen):\n",
    "\n",
    "    valid_data = list(zip(valid_files, valid_classes))\n",
    "  \n",
    "    while(True):\n",
    "        \n",
    "        for start in range(0, len(valid_data), batch_size):\n",
    "            image_crop_list = []\n",
    "            image_classes_list = []\n",
    "            end = min(start + batch_size, len(valid_data)) \n",
    "    \n",
    "            x_batch = [valid_data[i][0] for i in range(start,end)]\n",
    "            \n",
    "            for index,i in enumerate(x_batch):\n",
    "                image = mpimg.imread('../validation_224/' + i)\n",
    "                if(len(image.shape)<3):\n",
    "                        continue\n",
    "                #rand_num = random.randint(0,7)\n",
    "                \n",
    "                #augmented_image = image_aug_valid(image,rand_num)\n",
    "                #image = random_crop_valid(image,image_size)\n",
    "                image_crop_list.append(image)\n",
    "                image_classes_list.append(valid_data[start+index][1])\n",
    "                \n",
    "                del image\n",
    "               \n",
    "                #del aug_image_recrop\n",
    "            \n",
    "            \n",
    "            image_crop_list = [x/1. for x in image_crop_list]\n",
    "            #image_crop_list = [imggen.random_transform(x) for x in image_crop_list]\n",
    "            image_crop_list = [preprocess_input(x) for x in image_crop_list]\n",
    "            \n",
    "            x_batch = np.array(image_crop_list, np.float32)\n",
    "            y_batch = np.array(image_classes_list)         \n",
    "            \n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:21.993467Z",
     "start_time": "2018-02-02T14:01:21.817478Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_aug_generator = valid_gen(validation_generator.filenames,to_categorical(validation_generator.classes),batch_size,image_size,validation_datagen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:22.205668Z",
     "start_time": "2018-02-02T14:01:21.998009Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam(lr=2.5e-5),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T14:01:34.500613Z",
     "start_time": "2018-02-02T14:01:34.497088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(filepath='cacnn_network_2_4.hdf5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, epsilon=0.01),\n",
    "EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "CSVLogger('./4-metrics_1.csv'),\n",
    "TensorBoard(log_dir='logs_cacnn', write_graph=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T18:07:57.422249Z",
     "start_time": "2018-02-02T14:02:10.878802Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_crop_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-5eeb63f21ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(\n\u001b[0;32m----> 2\u001b[0;31m                     \u001b[0mtrain_crop_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_total\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_crop_generator' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "                    train_crop_generator,\n",
    "                    steps_per_epoch = 5*int(np.ceil(train_total/batch_size)),\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=valid_aug_generator,\n",
    "                    validation_steps= int(np.ceil(validation_total/batch_size)),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T18:34:45.082838Z",
     "start_time": "2018-02-02T18:34:44.977791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('cacnn_network_2_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T18:35:08.264372Z",
     "start_time": "2018-02-02T18:34:45.359244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34162709475265818, 0.91189931977531735]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(valid_aug_generator,int(np.ceil(validation_total/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T14:02:03.714369Z",
     "start_time": "2018-02-20T14:02:03.708972Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation predictions for futture ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('cacnn_network_2_3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cacnn_preds = model.predict_generator(valid_aug_generator,int(np.ceil(validation_total/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_filenames = np.load('filenames_list.npy')\n",
    "f = defaultdict(list)\n",
    "for i,j in enumerate(validation_generator.filenames):\n",
    "    f[j.split('/')[-1][2:]].append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_filenames=[]\n",
    "predicted_classes=[]\n",
    "for i in validation_filenames:\n",
    "    x = np.mean(cacnn_preds[f[i.split('/')[-1]]],axis=0)\n",
    "    result_filenames.append(i)\n",
    "    predicted_classes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('cacnn_preds_224.npy',predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('cacnn_preds.npy',cacnn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T14:02:48.266750Z",
     "start_time": "2018-02-20T14:02:48.260976Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test predicitons - 224 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames_list = []\n",
    "images_list = []\n",
    "for i in os.listdir('test_224/temp/'):\n",
    "    img = Image.open('test_224/temp/'+i)\n",
    "    filenames_list.append(i)\n",
    "    images_list.append(np.array(img, np.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13200, 224, 224, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_list = [preprocess_input(x) for x in images_list]\n",
    "new_array_arr = np.array(images_list)\n",
    "new_array_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_224 = model.predict(new_array_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = defaultdict(list)\n",
    "for i,j in enumerate(filenames_list):\n",
    "    f[j[2:]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filenames = np.load('test_filenames.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_filenames=[]\n",
    "predicted_classes=[]\n",
    "for i in test_filenames:\n",
    "    x = np.mean(test_preds_224[f[i.split('/')[-1]]],axis=0)\n",
    "    result_filenames.append(i)\n",
    "    predicted_classes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('cacnn_test_preds_224.npy',predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T14:02:41.453110Z",
     "start_time": "2018-02-20T14:02:41.449709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test predictions - 512 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_list = []\n",
    "for i in os.listdir('test/temp/')[1000:]:\n",
    "    img = Image.open('test/temp/'+i)\n",
    "    filenames_list.append(i)\n",
    "    images_list.append(np.array(img, np.float32))\n",
    "    del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_list = [x/1. for x in images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_list = [preprocess_input(x) for x in images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_list = np.array(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = model.predict(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds1 = model.predict(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filenames = np.load('test_filenames.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_test_preds = np.concatenate([test_preds,test_preds1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('cacnn_test_preds.npy',final_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_ids = {train_generator.class_indices[x]: x for x in train_generator.class_indices}\n",
    "predicted_classes = [class_ids[x] for x in np.argmax(test_preds, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(filenames_list):\n",
    "    if(i.split('_')[-1]=='manip.tif'):\n",
    "        predicted_classes[index]='HTC-1-M7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'fname':filenames_list,'camera':predicted_classes})\n",
    "submission.to_csv('submission_mobilenet_v2_test.csv', encoding=\"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_mobilenet_v2_test.csv' target='_blank'>submission_mobilenet_v2_test.csv</a><br>"
      ],
      "text/plain": [
       "/home/sainath/camera_model/submission_mobilenet_v2_test.csv"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission_mobilenet_v2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
