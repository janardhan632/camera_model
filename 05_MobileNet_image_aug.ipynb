{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:05.854013Z",
     "start_time": "2018-02-03T12:44:04.333388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, TensorBoard, LambdaCallback\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input \n",
    "from keras.layers import Conv2D, Convolution2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import load_model\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from collections import defaultdict\n",
    "import jpeg4py as jpeg\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:05.859426Z",
     "start_time": "2018-02-03T12:44:05.855600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "classes = 10\n",
    "batch_size=80\n",
    "image_size = 512\n",
    "train_total = 3500\n",
    "validation_total = 875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:08.306552Z",
     "start_time": "2018-02-03T12:44:06.008134Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_mobilenet = MobileNet(include_top=False, weights = None,input_shape=(image_size,image_size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:08.526454Z",
     "start_time": "2018-02-03T12:44:08.340333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = model_mobilenet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:08.531117Z",
     "start_time": "2018-02-03T12:44:08.528102Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model_mobilenet.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:08.580338Z",
     "start_time": "2018-02-03T12:44:08.540353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 256, 256, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 256, 256, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 256, 256, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 256, 256, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 128, 128, 64)      576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 128, 128, 128)     8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 128, 128, 128)     1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 128, 128, 128)     16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 128, 128, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 64, 64, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 64, 64, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 64, 64, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 64, 64, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 32, 32, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 32, 32, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 32, 32, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 32, 32, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 16, 16, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 16, 16, 1024)      524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 16, 16, 1024)      9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 16, 16, 1024)      1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 16, 16, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 16, 16, 1024)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 3,526,986\n",
      "Trainable params: 3,504,330\n",
      "Non-trainable params: 22,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=model_mobilenet.input, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:12.621089Z",
     "start_time": "2018-02-03T12:44:12.617153Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:27:23.148109Z",
     "start_time": "2018-02-03T12:26:32.317589Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 790600 images belonging to 10 classes.\n",
      "Found 875 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    'train',\n",
    "                    target_size=(image_size,image_size),\n",
    "                    batch_size=batch_size,\n",
    "                    class_mode='categorical',\n",
    "                    shuffle=True\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:13.699962Z",
     "start_time": "2018-02-03T12:44:13.590305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 875 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                        'validation',\n",
    "                        target_size=(image_size,image_size),\n",
    "                        batch_size=batch_size,\n",
    "                        class_mode='categorical',\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:15.492161Z",
     "start_time": "2018-02-03T12:44:15.469173Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_aug_valid(image, index):\n",
    "    Image.LOAD_TRUNCATED_IMAGES = True\n",
    "    mpimg.LOAD_TRUNCATED_IMAGES = True\n",
    "    if(index==0):\n",
    "        res_image = np.uint8(cv2.pow(image/255.,0.8)*255.)\n",
    "    elif(index==1):\n",
    "        res_image = np.uint8(cv2.pow(image/255.,1.2)*255.)\n",
    "    elif(index==2):\n",
    "        res_image = cv2.resize(image,(0,0),fx=0.5,fy=0.5,interpolation = cv2.INTER_CUBIC)\n",
    "    elif(index==3):\n",
    "        res_image = cv2.resize(image,(0,0),fx=0.8,fy=0.8,interpolation = cv2.INTER_CUBIC)    \n",
    "    elif(index==4):\n",
    "        res_image = cv2.resize(image,(0,0),fx=1.5,fy=1.5,interpolation = cv2.INTER_CUBIC)\n",
    "    elif(index==5):\n",
    "        res_image = cv2.resize(image,(0,0),fx=2.0,fy=2.0,interpolation = cv2.INTER_CUBIC)\n",
    "    elif(index==6):\n",
    "        img = Image.fromarray(image)\n",
    "        out_70_valid = BytesIO()\n",
    "        img.save(out_70_valid, \"JPEG\", quality=70)\n",
    "        res_image = jpeg.JPEG(np.frombuffer(out_70_valid.getvalue(), dtype=np.uint8)).decode()\n",
    "        del img\n",
    "        del out_70_valid\n",
    "    elif(index==7):\n",
    "        img = Image.fromarray(image)\n",
    "        out_90_valid = BytesIO()\n",
    "        img.save(out_90_valid, \"JPEG\", quality=90)\n",
    "        res_image = jpeg.JPEG(np.frombuffer(out_90_valid.getvalue(), dtype=np.uint8)).decode()\n",
    "        del img\n",
    "        del out_90_valid\n",
    "    return res_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:16.096459Z",
     "start_time": "2018-02-03T12:44:16.072113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_aug(image, index):\n",
    "    Image.LOAD_TRUNCATED_IMAGES = True\n",
    "    mpimg.LOAD_TRUNCATED_IMAGES = True\n",
    "    if(index==0):\n",
    "        res_image = np.uint8(cv2.pow(image/255.,0.8)*255.)\n",
    "    elif(index==1):\n",
    "        res_image = np.uint8(cv2.pow(image/255.,1.2)*255.)\n",
    "    elif(index==2):\n",
    "        res_image = cv2.resize(image,(0,0),fx=0.5,fy=0.5,interpolation = cv2.INTER_CUBIC)\n",
    "    elif(index==3):\n",
    "        res_image = cv2.resize(image,(0,0),fx=0.8,fy=0.8,interpolation = cv2.INTER_CUBIC)    \n",
    "    elif(index==4):\n",
    "        res_image = cv2.resize(image,(0,0),fx=1.5,fy=1.5,interpolation = cv2.INTER_CUBIC)\n",
    "    elif(index==5):\n",
    "        res_image = cv2.resize(image,(0,0),fx=2.0,fy=2.0,interpolation = cv2.INTER_CUBIC)\n",
    "    elif(index==6):\n",
    "        img = Image.fromarray(image)\n",
    "        out_70 = BytesIO()\n",
    "        img.save(out_70, \"JPEG\", quality=70)\n",
    "        res_image = jpeg.JPEG(np.frombuffer(out_70.getvalue(), dtype=np.uint8)).decode()\n",
    "        del img\n",
    "        del out_70\n",
    "    elif(index==7):\n",
    "        img = Image.fromarray(image)\n",
    "        out_90 = BytesIO()\n",
    "        img.save(out_90, \"JPEG\", quality=90)\n",
    "        res_image = jpeg.JPEG(np.frombuffer(out_90.getvalue(), dtype=np.uint8)).decode()\n",
    "        del img\n",
    "        del out_90\n",
    "    return res_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:16.355995Z",
     "start_time": "2018-02-03T12:44:16.351152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_crop(image, crop_size):\n",
    "    h,w,d = image.shape\n",
    "    rand_num_h = random.randint(0,h-crop_size)\n",
    "    rand_num_w = random.randint(0,w-crop_size)\n",
    "    image_crop = image[rand_num_h:rand_num_h+crop_size,rand_num_w:rand_num_w+crop_size,:]\n",
    "    return image_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:16.702649Z",
     "start_time": "2018-02-03T12:44:16.658496Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gen(train_files, train_classes, batch_size, target_size, imggen):\n",
    "    min_batch_size = batch_size //10\n",
    "    train_data = list(zip(train_files, train_classes))\n",
    "    train_data_dict = defaultdict(list)\n",
    "    for i in range(len(train_data)):\n",
    "        train_data_dict[train_data[i][0].split('/')[0]].append(train_data[i])\n",
    "       \n",
    "    while(True):\n",
    "        for i in train_data_dict.keys():\n",
    "            random.shuffle(train_data_dict[i])\n",
    "        for start in range(0, len(train_data), min_batch_size):\n",
    "            image_crop_list = []\n",
    "            image_classes_list = []\n",
    "            \n",
    "            \n",
    "            for j in train_data_dict.keys():\n",
    "                end = min(start + min_batch_size, len(train_data_dict[j])) \n",
    "                \n",
    "                x_batch = [train_data_dict[j][i][0] for i in range(start,end)]\n",
    "                \n",
    "                for index,i in enumerate(x_batch):\n",
    "                    image = jpeg.JPEG('train/' + i).decode()\n",
    "                    \n",
    "                    if(len(image.shape)<3):\n",
    "                        print(_1_)\n",
    "                        continue\n",
    "                    rand_num = random.randint(0,7)\n",
    "                    \n",
    "                    augmented_image = image_aug(image,rand_num)\n",
    "                    aug_image_recrop = random_crop(augmented_image,image_size)\n",
    "                    if(np.random.rand()<0.1):\n",
    "                        aug_image_recrop = np.rot90(aug_image_recrop,1,(0,1))\n",
    "                    image_crop_list.append(aug_image_recrop)\n",
    "                    image_classes_list.append(train_data_dict[j][start+index][1])\n",
    "                    \n",
    "                    del image\n",
    "                    del aug_image_recrop\n",
    "            \n",
    "            if(len(image_classes_list)<batch_size-2*min_batch_size):\n",
    "                break\n",
    "            image_crop_list = [x/1. for x in image_crop_list]\n",
    "            image_crop_list = [imggen.random_transform(x) for x in image_crop_list]\n",
    "            image_crop_list = [preprocess_input(x) for x in image_crop_list]\n",
    "\n",
    "            x_batch = np.array(image_crop_list, np.float32)\n",
    "            y_batch = np.array(image_classes_list)         \n",
    "            \n",
    "            yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:37:45.377430Z",
     "start_time": "2018-02-03T12:37:45.362551Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_crop_generator = train_gen(train_generator.filenames,to_categorical(train_generator.classes),batch_size,image_size,train_datagen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:18.137099Z",
     "start_time": "2018-02-03T12:44:18.106846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_gen(valid_files, valid_classes, batch_size, target_size, imggen):\n",
    "\n",
    "    valid_data = list(zip(valid_files, valid_classes))\n",
    "  \n",
    "    while(True):\n",
    "        \n",
    "        for manip_num in range(8):\n",
    "            for start in range(0, len(valid_data), batch_size):\n",
    "                image_crop_list = []\n",
    "                image_classes_list = []\n",
    "                end = min(start + batch_size, len(valid_data)) \n",
    "\n",
    "                x_batch = [valid_data[i][0] for i in range(start,end)]\n",
    "\n",
    "                for index,i in enumerate(x_batch):\n",
    "                    if(manip_num == 2 or manip_num == 3):\n",
    "                        temp_file = random.choice(os.listdir('validation_full_size/'+i.split('/')[0]))\n",
    "                        image = jpeg.JPEG('validation_full_size/' + i.split('/')[0]+'/' + temp_file).decode()\n",
    "                    else:\n",
    "                        image = jpeg.JPEG('validation/' + i).decode() \n",
    "                    if(len(image.shape)<3):\n",
    "                            continue\n",
    "                    #rand_num = random.randint(0,7)\n",
    "\n",
    "                    #augmented_image = image_aug_valid(image,manip_num)\n",
    "                    aug_image_recrop = random_crop(image,image_size)\n",
    "                    image_crop_list.append(aug_image_recrop)\n",
    "                    image_classes_list.append(valid_data[start+index][1])\n",
    "\n",
    "                    del image\n",
    "                    del aug_image_recrop\n",
    "\n",
    "\n",
    "                image_crop_list = [x/1. for x in image_crop_list]\n",
    "                image_crop_list = [preprocess_input(x) for x in image_crop_list]\n",
    "\n",
    "                x_batch = np.array(image_crop_list, np.float32)\n",
    "                y_batch = np.array(image_classes_list)         \n",
    "\n",
    "                yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:18.549791Z",
     "start_time": "2018-02-03T12:44:18.546681Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_aug_generator = valid_gen(validation_generator.filenames,to_categorical(validation_generator.classes),batch_size,image_size,validation_datagen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:19.213861Z",
     "start_time": "2018-02-03T12:44:19.181678Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam(lr=2.5e-5),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:19.828619Z",
     "start_time": "2018-02-03T12:44:19.497858Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pushbullet import Pushbullet\n",
    "pb = Pushbullet('o.KiDDDXPuzV4qKbXh4Lywbgw1tK2oFfq1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:20.163829Z",
     "start_time": "2018-02-03T12:44:20.160052Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pushbullet_callback = LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: pb.push_note(\"epoch: \"+str(epoch),\"train_loss: \"+str(logs['loss'])+\"    val_loss\"+str(logs['val_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:44:21.558379Z",
     "start_time": "2018-02-03T12:44:20.972873Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(filepath='mobilenet_image_aug_3.hdf5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1,epsilon=0.01),\n",
    "#EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "CSVLogger('./3-metrics_mobilenet_image_aug.csv'),\n",
    "TensorBoard(log_dir='logs_mobilenet_image_aug', write_graph=True),\n",
    "            pushbullet_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-03T05:39:01.515Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1839 - acc: 0.9460\n",
      "Epoch 00001: val_loss improved from inf to 0.34917, saving model to mobilenet_image_aug_3.hdf5\n",
      "880/880 [==============================] - 878s 998ms/step - loss: 0.1838 - acc: 0.9460 - val_loss: 0.3492 - val_acc: 0.9056\n",
      "Epoch 2/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9477\n",
      "Epoch 00002: val_loss did not improve\n",
      "880/880 [==============================] - 884s 1s/step - loss: 0.1762 - acc: 0.9477 - val_loss: 0.3592 - val_acc: 0.9013\n",
      "Epoch 3/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9471\n",
      "Epoch 00003: val_loss did not improve\n",
      "880/880 [==============================] - 880s 1000ms/step - loss: 0.1781 - acc: 0.9471 - val_loss: 0.3594 - val_acc: 0.9020\n",
      "Epoch 4/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9475\n",
      "Epoch 00004: val_loss did not improve\n",
      "880/880 [==============================] - 867s 986ms/step - loss: 0.1772 - acc: 0.9475 - val_loss: 0.3619 - val_acc: 0.9003\n",
      "Epoch 5/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9491\n",
      "Epoch 00005: val_loss improved from 0.34917 to 0.34350, saving model to mobilenet_image_aug_3.hdf5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "880/880 [==============================] - 861s 978ms/step - loss: 0.1745 - acc: 0.9491 - val_loss: 0.3435 - val_acc: 0.9057\n",
      "Epoch 6/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9515\n",
      "Epoch 00006: val_loss improved from 0.34350 to 0.32468, saving model to mobilenet_image_aug_3.hdf5\n",
      "880/880 [==============================] - 858s 975ms/step - loss: 0.1668 - acc: 0.9515 - val_loss: 0.3247 - val_acc: 0.9101\n",
      "Epoch 7/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9506\n",
      "Epoch 00007: val_loss did not improve\n",
      "880/880 [==============================] - 845s 960ms/step - loss: 0.1706 - acc: 0.9505 - val_loss: 0.3341 - val_acc: 0.9059\n",
      "Epoch 8/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9472\n",
      "Epoch 00008: val_loss did not improve\n",
      "880/880 [==============================] - 766s 871ms/step - loss: 0.1796 - acc: 0.9472 - val_loss: 0.3665 - val_acc: 0.9006\n",
      "Epoch 9/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9457\n",
      "Epoch 00009: val_loss did not improve\n",
      "880/880 [==============================] - 714s 811ms/step - loss: 0.1907 - acc: 0.9457 - val_loss: 0.3631 - val_acc: 0.9007\n",
      "Epoch 10/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9506\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "880/880 [==============================] - 784s 891ms/step - loss: 0.1695 - acc: 0.9506 - val_loss: 0.3541 - val_acc: 0.9069\n",
      "Epoch 11/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9533\n",
      "Epoch 00011: val_loss did not improve\n",
      "880/880 [==============================] - 789s 897ms/step - loss: 0.1588 - acc: 0.9534 - val_loss: 0.3593 - val_acc: 0.9027\n",
      "Epoch 12/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9530\n",
      "Epoch 00012: val_loss did not improve\n",
      "880/880 [==============================] - 800s 909ms/step - loss: 0.1603 - acc: 0.9530 - val_loss: 0.3262 - val_acc: 0.9104\n",
      "Epoch 13/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9530\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "880/880 [==============================] - 804s 913ms/step - loss: 0.1609 - acc: 0.9530 - val_loss: 0.3331 - val_acc: 0.9073\n",
      "Epoch 14/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9548\n",
      "Epoch 00014: val_loss did not improve\n",
      "880/880 [==============================] - 833s 946ms/step - loss: 0.1539 - acc: 0.9549 - val_loss: 0.3274 - val_acc: 0.9111\n",
      "Epoch 15/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9556\n",
      "Epoch 00015: val_loss did not improve\n",
      "880/880 [==============================] - 830s 943ms/step - loss: 0.1526 - acc: 0.9555 - val_loss: 0.3315 - val_acc: 0.9120\n",
      "Epoch 16/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9492\n",
      "Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "880/880 [==============================] - 812s 923ms/step - loss: 0.1713 - acc: 0.9492 - val_loss: 0.3422 - val_acc: 0.9063\n",
      "Epoch 17/100\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9405\n",
      "Epoch 00017: val_loss did not improve\n",
      "880/880 [==============================] - 738s 838ms/step - loss: 0.2033 - acc: 0.9405 - val_loss: 0.3846 - val_acc: 0.8983\n",
      "Epoch 18/100\n",
      "188/880 [=====>........................] - ETA: 7:54 - loss: 0.2272 - acc: 0.9323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1c5dea06ffa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_total\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/janardhan/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                    train_crop_generator,\n",
    "                    steps_per_epoch = 20*int(np.ceil(train_total/batch_size)),\n",
    "                    epochs=100,\n",
    "                    validation_data=valid_aug_generator,\n",
    "                    validation_steps= 8*int(np.ceil(validation_total/batch_size)),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:46:36.899774Z",
     "start_time": "2018-02-03T12:46:36.718817Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('mobilenet_96_2_LB_unalt.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:28:57.280902Z",
     "start_time": "2018-02-03T12:27:26.738568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11509572395722249, 0.97228571823665078]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(valid_aug_generator,8*int(np.ceil(validation_total/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation predictions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_valid = model.predict_generator(validation_generator,int(np.ceil(validation_total/batch_size)))\n",
    "predictions_valid = np.argmax(predictions_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HTC-1-M7': 0,\n",
       " 'LG-Nexus-5x': 1,\n",
       " 'Motorola-Droid-Maxx': 2,\n",
       " 'Motorola-Nexus-6': 3,\n",
       " 'Motorola-X': 4,\n",
       " 'Samsung-Galaxy-Note3': 5,\n",
       " 'Samsung-Galaxy-S4': 6,\n",
       " 'Sony-NEX-7': 7,\n",
       " 'iPhone-4s': 8,\n",
       " 'iPhone-6': 9}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_positive = np.zeros(10)\n",
    "false_positive = np.zeros(10)\n",
    "true_negative = np.zeros(10)\n",
    "false_negative = np.zeros(10)\n",
    "for i in range(len(predictions_valid)):\n",
    "    if(predictions_valid[i]==validation_generator.classes[i]):\n",
    "        true_positive[predictions_valid[i]] = true_positive[predictions_valid[i]] + 1\n",
    "    else:\n",
    "        false_positive[predictions_valid[i]] = false_positive[predictions_valid[i]] + 1\n",
    "        false_negative[validation_generator.classes[i]] = false_negative[validation_generator.classes[i]] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positive\n",
      "[ 86.  72.  53.  53.  62.  64.  82.  68.  68.  81.]\n",
      "false_positive\n",
      "[ 16.  27.   5.  19.  31.  22.  12.   7.   8.  39.]\n",
      "false_negative\n",
      "[ 12.  27.  22.  24.  24.  12.  17.  18.  20.  10.]\n",
      "Total\n",
      "[ 98.  99.  75.  77.  86.  76.  99.  86.  88.  91.]\n"
     ]
    }
   ],
   "source": [
    "print('true_positive')\n",
    "print(true_positive)\n",
    "print('false_positive')\n",
    "print(false_positive)\n",
    "print('false_negative')\n",
    "print(false_negative)\n",
    "print('Total')\n",
    "print(true_positive+false_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T14:16:16.148299Z",
     "start_time": "2018-02-20T14:16:16.145366Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test predictions - 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:45:12.188645Z",
     "start_time": "2018-02-03T12:44:39.288234Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames_list = []\n",
    "images_list = []\n",
    "for i in os.listdir('test/temp/'):\n",
    "    img = Image.open('test/temp/'+i)\n",
    "    filenames_list.append(i)\n",
    "    images_list.append(np.array(img, np.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:45:13.907583Z",
     "start_time": "2018-02-03T12:45:12.190356Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_list = [np.rot90(x,3,(0,1)) for x in images_list]\n",
    "images_list = [preprocess_input(x) for x in images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:45:18.629615Z",
     "start_time": "2018-02-03T12:45:13.909257Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_array_arr = np.array(images_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:45:18.636231Z",
     "start_time": "2018-02-03T12:45:18.631355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640, 512, 512, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:45:40.989243Z",
     "start_time": "2018-02-03T12:45:18.637839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_1 = model.predict(new_array_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mobilenet_512_test_preds_1_unalt.npy',test_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_2 = model.predict(new_array_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mobilenet_512_test_preds_2_unalt.npy',test_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_3 = model.predict(new_array_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mobilenet_512_test_preds_3_unalt.npy',test_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_1_unalt = np.load('mobilenet_512_test_preds_1_unalt.npy')\n",
    "test_preds_2_unalt = np.load('mobilenet_512_test_preds_2_unalt.npy')\n",
    "test_preds_3_unalt = np.load('mobilenet_512_test_preds_3_unalt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_1_manip = np.load('mobilenet_512_test_preds_1_manip.npy')\n",
    "test_preds_2_manip = np.load('mobilenet_512_test_preds_2_manip.npy')\n",
    "test_preds_3_manip = np.load('mobilenet_512_test_preds_3_manip.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(filenames_list):\n",
    "    if(i.split('_')[-1]=='manip.tif'):\n",
    "        test_preds_1_unalt[index] = test_preds_1_manip[index]\n",
    "        test_preds_2_unalt[index] = test_preds_2_manip[index]\n",
    "        test_preds_3_unalt[index] = test_preds_3_manip[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2640, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_1_unalt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mobilenet_512_test_preds_1.npy',test_preds_1_unalt)\n",
    "np.save('mobilenet_512_test_preds_2.npy',test_preds_2_unalt)\n",
    "np.save('mobilenet_512_test_preds_3.npy',test_preds_3_unalt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:48:13.231473Z",
     "start_time": "2018-02-03T12:48:13.215528Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_classes_manip = [class_ids[np.argmax(i)] for i in test_preds]\n",
    "predicted_classes_unalt = [class_ids[np.argmax(i)] for i in test_preds_unalt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:38:26.875477Z",
     "start_time": "2018-02-03T12:37:58.877970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13200, 224, 224, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_list_224 = []\n",
    "images_list_224 = []\n",
    "for i in os.listdir('test_224/temp/'):\n",
    "    img = Image.open('test_224/temp/'+i)\n",
    "    filenames_list_224.append(i)\n",
    "    images_list_224.append(np.array(img, np.float32))\n",
    "    \n",
    "images_list_224 = [preprocess_input(x) for x in images_list_224]\n",
    "images_list_224 = np.array(images_list_224)\n",
    "images_list_224.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:38:46.089373Z",
     "start_time": "2018-02-03T12:38:26.877203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_224 = model.predict(images_list_224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:38:46.102552Z",
     "start_time": "2018-02-03T12:38:46.091080Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = defaultdict(list)\n",
    "for i,j in enumerate(filenames_list_224):\n",
    "    f[j[2:]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:48:09.500773Z",
     "start_time": "2018-02-03T12:48:09.497631Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_ids = {validation_generator.class_indices[x]: x for x in validation_generator.class_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:39:43.165754Z",
     "start_time": "2018-02-03T12:39:43.093619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_224_dict  = defaultdict(list)\n",
    "for i in f.keys():\n",
    "    x = np.mean(test_preds_224[f[i]],axis=0)\n",
    "    res_224_dict[i].append(class_ids[np.argmax(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:40:59.885709Z",
     "start_time": "2018-02-03T12:40:59.787832Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_filenames_224=[]\n",
    "predicted_classes_224=[]\n",
    "for i in f.keys():\n",
    "    \n",
    "    x = np.mean(test_preds_224[f[i]],axis=0)\n",
    "    result_filenames_224.append(i)\n",
    "    predicted_classes_224.append(class_ids[np.argmax(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('resnet_image_aug_full.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35670383436871428, 0.90357143240315574]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(valid_aug_generator,8*int(np.ceil(validation_total/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_unalt = model.predict(new_array_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_avg = (test_preds+test_preds_unalt)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_filenames=[]\n",
    "predicted_classes=[]\n",
    "for i in f.keys():\n",
    "    if(i.split('_')[-1]=='manip.tif'):\n",
    "        x = np.mean(test_preds[f[i]],axis=0)\n",
    "        result_filenames.append(i)\n",
    "    else:\n",
    "        x = np.mean(test_preds[f[i]],axis=0)\n",
    "        result_filenames.append(i)\n",
    "    predicted_classes.append(class_ids[np.argmax(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:30:09.490566Z",
     "start_time": "2018-02-03T12:30:09.480569Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_classes = [class_ids[np.argmax(i)] for i in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:50:07.886475Z",
     "start_time": "2018-02-03T12:50:07.881020Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(filenames_list):\n",
    "    if(i.split('_')[-1]=='manip.tif'):\n",
    "        predicted_classes_unalt[index]=predicted_classes_manip[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:50:39.977959Z",
     "start_time": "2018-02-03T12:50:39.966933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'fname':filenames_list,'camera':predicted_classes_unalt})\n",
    "submission.to_csv('submission_mobilenet_512.csv', encoding=\"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T12:50:45.866546Z",
     "start_time": "2018-02-03T12:50:45.861889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_mobilenet_512.csv' target='_blank'>submission_mobilenet_512.csv</a><br>"
      ],
      "text/plain": [
       "/home/janardhan/camera_model/submission_mobilenet_512.csv"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission_mobilenet_512.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T14:26:51.014496Z",
     "start_time": "2018-02-20T14:26:51.009933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only mobilenet - unalt+ manip - Private LB score - 96.39"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
